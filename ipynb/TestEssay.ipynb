{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a9eb90-335c-4214-8bb6-fd1edbe3ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My OpenAI Key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a712b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f7baa-1c0a-430b-981b-83ddca9e71f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using GPT Tree Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881f151-279e-4910-95c7-f49d3d6a4c69",
   "metadata": {},
   "source": [
    "#### [Demo] Default leaf traversal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0b2364-4806-4656-81e7-3f6e4b910b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import GPTTreeIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c297fd3-3424-41d8-9d0d-25fe6310ab62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1b560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psy_documents = SimpleDirectoryReader('data/psy').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba7292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "His_documents = SimpleDirectoryReader('data/his').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5299c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_documents = SimpleDirectoryReader('data/phi').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370fd08f-56ff-4c24-b0c4-c93116a6d482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 4 chunks\n",
      "> Building index from nodes: 4 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 14948 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 14948 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTTreeIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732548a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 16 chunks\n",
      "> Building index from nodes: 16 chunks\n",
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 1 chunks\n",
      "> Building index from nodes: 1 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 65798 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 65798 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "index2 = GPTTreeIndex(Psy_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a3d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 22 chunks\n",
      "> Building index from nodes: 22 chunks\n",
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 2 chunks\n",
      "> Building index from nodes: 2 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 91998 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 91998 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "index3 = GPTTreeIndex(His_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b71b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 38 chunks\n",
      "> Building index from nodes: 38 chunks\n",
      "INFO:llama_index.indices.common.tree.base:> Building index from nodes: 3 chunks\n",
      "> Building index from nodes: 3 chunks\n"
     ]
    }
   ],
   "source": [
    "index4 = GPTTreeIndex(Phi_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fe9b6-5762-4e86-b51e-aac45d3ecdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save_to_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c590805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2.save_to_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f5e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index3.save_to_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585983eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index4.save_to_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eec265d-211b-4f26-b05b-5b4e7072bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try loading\n",
    "new_index = GPTTreeIndex.load_from_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14686d-1c53-4637-9340-3745f2121ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response = new_index.query(\"根據Gorgias的文章內容，我應該要怎麼分段會比較好？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c87d14-d2d8-4d80-89f6-1e5972973528",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c9ebfe-b1b6-4f4e-9278-174346de8c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.query.tree.leaf_query:> Starting query: 請把《清雍正乾隆時期台灣米價分析》中，表一 :雍、乾時期各月份米價表，以markdown畫給我\n",
      "> Starting query: 請把《清雍正乾隆時期台灣米價分析》中，表一 :雍、乾時期各月份米價表，以markdown畫給我\n",
      "INFO:llama_index.indices.query.tree.leaf_query:>[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Selected node: [2]/[2]\n",
      "INFO:llama_index.indices.query.tree.leaf_query:>[Level 1] Selected node: [7]/[7]\n",
      ">[Level 1] Selected node: [7]/[7]\n",
      "INFO:llama_index.indices.query.tree.leaf_query:>[Level 2] Selected node: [5]/[5]\n",
      ">[Level 2] Selected node: [5]/[5]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 8096 tokens\n",
      "> [query] Total LLM token usage: 8096 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
      "> [query] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response = new_index.query(\"請把《清雍正乾隆時期台灣米價分析》中，表一 :雍、乾時期各月份米價表，以markdown畫給我\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5ab5943-7c84-4c2b-ac99-ec4b5fc67e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>| Month | Price |\n",
       "|-------|-------|\n",
       "| April | 5-8 |\n",
       "| May | 5-8 |\n",
       "| June | 5-8 |\n",
       "| July | 5-8 |\n",
       "| August | 5-8 |\n",
       "| September | 5-8 |\n",
       "| October | 5-8 |\n",
       "| November | 5-8 |\n",
       "| December | 5-8 |</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c62ec3-c3cf-467e-ab0f-88ffb9f990be",
   "metadata": {},
   "source": [
    "#### [Demo] Leaf traversal with child_branch_factor=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46714db4-9592-4c55-9ca7-916758f2ce68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try using branching factor 2\n",
    "response = new_index.query(\"根據Practitioner Review: Borderline personality disorder in adolescence: recent conceptualization, intervention, and implications for clinical practice.那篇論文中的table_2中各種measure在統計數據上的表現，從Specificity來看，是不是BPQ Chanen, Jovev, et al. (2008)在辨別為陽性有比較好的成效？\", child_branch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ea7f891-b7e1-497a-a965-14201b220404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Based on Table 2 in the Practitioner Review: Borderline Personality Disorder in Adolescence: Recent Conceptualization, Intervention, and Implications for Clinical Practice, which takes into account the research from Reif et al. (2007), Roth et al. (1990), Rollnik et al. (2001), Rothschild and Rand (2006), Salsman & Linehan (2006), Samuels et al. (1994), Sansone et al. (2005), Sar et al. (2006), Scheirs & Bok (2007), Semiz et al. (2007, 2008), Siegle (2007), Silbersweig et al. (2007), Silverman et al. (1991), Smith (2006), Sperry (2006), Thuo et al. (2008), Torgersen (2000, 1984), Troisi (2007), Ussher (2013), Verheul et al. (2007), Vizard et al. (2007), Volkan (1994), Watson et al. (2006), Wilson et al. (2007), and Zanarini et al. (2006), does the BPQ Chanen, Jovev, et al. (2008) have better performance in terms of specificity when it comes to identifying</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c572726-bb95-49c3-a762-d966de59ee5f",
   "metadata": {},
   "source": [
    "#### [Demo] Build Tree Index during Query-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255fb052-1ff6-4f27-881f-28d4790e9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85371256-292c-473e-9485-7de5c1997a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_light = GPTTreeIndex(documents, build_tree=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0acb3-5593-4f00-8eef-315a031fedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_light.query(\"What did the author do after his time at Y Combinator?\", mode=\"summarize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9773497-9aa6-4a16-884a-cd882e63d012",
   "metadata": {},
   "source": [
    "#### [Demo] Build Tree Index with a custom Summary Prompt, directly retrieve answer from root node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6d3ad-95e1-477a-a0dc-2ce4763ff2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SummaryPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91a445-6ab2-457c-850e-79c5386129db",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "\n",
    "query_str = \"What did the author do growing up?\"\n",
    "SUMMARY_PROMPT_TMPL = (\n",
    "    \"Context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    f\"answer the question: {query_str}\\n\"\n",
    ")\n",
    "SUMMARY_PROMPT = SummaryPrompt(SUMMARY_PROMPT_TMPL)\n",
    "index_with_query = GPTTreeIndex(documents, summary_template=SUMMARY_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dad0c-1ede-4576-a4c9-c077b815edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_with_query.save_to_disk(\"index_with_query.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04fce5-88f9-41b7-87d9-dcde8f84a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_with_query = GPTTreeIndex.load_from_disk(\"index_with_query.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223ffa8-d49d-4de3-821a-701b2a0352d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly retrieve response from root nodes instead of traversing tree\n",
    "response = index_with_query.query(query_str, mode=\"retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca6970-2f3f-4741-ae98-555db8d3d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6457769-dfaf-4241-ab32-dcf901dde902",
   "metadata": {},
   "source": [
    "## Using GPT Keyword Table Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d59ef6-70b0-47bb-818d-7237a3b7de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTKeywordTableIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f1c67-6d73-4f37-afcf-9e637002fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keyword index\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = GPTKeywordTableIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec97988-0190-4df7-b19a-e3130122298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index\n",
    "index.save_to_disk('index_table.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d0fe0-43c1-41cd-901b-0d748d30f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload index\n",
    "index = GPTKeywordTableIndex.load_from_disk('index_table.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4f686-6825-49cf-a113-d2fdd484de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response = index.query(\"What did the author do after his time at Y Combinator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483514d-4ab5-489d-8b99-7250df491ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1bea9-b534-430a-a52b-1f4414957ac9",
   "metadata": {},
   "source": [
    "## Using GPT List Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8c8c1-7fce-4737-9141-d14fd37a779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTListIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191caa65-a77f-4d8c-b095-4aed61300ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linked list index\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = GPTListIndex(documents)\n",
    "# save index\n",
    "index.save_to_disk('index_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d049d-518d-4ec4-b84f-1fab8aece04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "index = GPTListIndex.load_from_disk('index_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d4bd8-7540-4c6f-8616-ab2d8c6ae2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response = index.query(\"What did the author do after his time at Y Combinator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101b979-175f-490e-9b32-27689fe4b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfce56-853e-431b-888e-946771c3b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba734902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_essay(query_str, document_path):\n",
    "    from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader\n",
    "    documents = SimpleDirectoryReader(document_path).load_data()\n",
    "    index = GPTSimpleVectorIndex(documents)\n",
    "    response = index.query(query_str)\n",
    "    return response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query_str = \"What did the author do growing up?\"\n",
    "    document_path = \"data\"\n",
    "    print(test_essay(query_str, document_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c61800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
